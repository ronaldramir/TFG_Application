import streamlit as st

st.set_page_config(
    page_title="Web Scraping | Adquisici√≥n de datos",
    page_icon="üï∑Ô∏è",
    layout="centered"
)

# ------------------------------------------------------------
# HERO
# ------------------------------------------------------------
with st.container(border=True):
    st.title("üï∑Ô∏è Origen y adquisici√≥n de los datos")
    st.caption("Web scraping controlado y segmentado sobre anuncios p√∫blicos de Crautos.com")
    st.markdown("**Objetivo:** recolectar atributos visibles de anuncios de veh√≠culos usados para construir el dataset del proyecto.")

st.write("")

# ------------------------------------------------------------
# Fuente de datos
# ------------------------------------------------------------
with st.container(border=True):
    st.header("üåê Fuente de datos")
    st.markdown("""
Los datos provienen del sitio web p√∫blico **Crautos.com**, espec√≠ficamente de su secci√≥n de veh√≠culos usados.  
La extracci√≥n se limita a informaci√≥n visible en los anuncios publicados, incluyendo:
- Atributos t√©cnicos del veh√≠culo  
- Variables comerciales del anuncio  
- Atributos de ubicaci√≥n y presentaci√≥n  
""")

st.write("")

# ------------------------------------------------------------
# Estrategia de recolecci√≥n
# ------------------------------------------------------------
with st.container(border=True):
    st.header("üß© Estrategia de recolecci√≥n")
    st.markdown("""
Debido al volumen de anuncios y a la necesidad de estabilidad operativa durante la extracci√≥n, se implement√≥ una estrategia de scraping **controlado y segmentado por rango de a√±os** (por ejemplo, `YEAR_FROM` a `YEAR_TO`), ejecutando corridas independientes por segmentos (a√±o por a√±o o rangos peque√±os).  
Esto permiti√≥:
- Reducir la carga por corrida y mejorar la estabilidad del proceso  
- Facilitar reintentos y reanudaci√≥n en caso de fallos  
- Minimizar p√©rdidas de progreso ante errores temporales del sitio o del navegador  

Adicionalmente, se restringi√≥ la b√∫squeda a veh√≠culos usados (`newused = 0`) para asegurar consistencia con el objetivo del proyecto.
""")

st.write("")

# ------------------------------------------------------------
# Herramientas y configuraci√≥n t√©cnica
# ------------------------------------------------------------
with st.container(border=True):
    st.header("üõ†Ô∏è Herramientas y configuraci√≥n t√©cnica")
    st.markdown("""
La extracci√≥n se desarroll√≥ en **Python** utilizando **Selenium** con **Microsoft Edge WebDriver**.  
El flujo de navegaci√≥n automatizada consider√≥:
- Carga del formulario de b√∫squeda  
- Selecci√≥n de filtros (a√±o desde/hasta; condici√≥n ‚Äúusados‚Äù)  
- Manejo de resultados paginados  
- Apertura del detalle del anuncio en una pesta√±a nueva para extraer variables  

Se incorporaron configuraciones orientadas a robustez: **timeouts**, **esperas expl√≠citas** y control de interacci√≥n con elementos.
""")

st.write("")

# ------------------------------------------------------------
# Flujo de extracci√≥n (alto nivel)
# ------------------------------------------------------------
with st.container(border=True):
    st.header("üîÅ Flujo de extracci√≥n (alto nivel)")
    st.markdown("""
El pipeline de adquisici√≥n sigui√≥ este flujo:

1. Ejecutar b√∫squeda con filtros definidos (rango de a√±os y condici√≥n ‚Äúusados‚Äù).  
2. Iterar sobre la paginaci√≥n hasta la √∫ltima p√°gina.  
3. En cada p√°gina, identificar los resultados (‚Äúcards‚Äù) y para cada veh√≠culo:  
   - Obtener `car_id` y `detail_url`  
   - Abrir detalle en una pesta√±a nueva  
   - Extraer variables del encabezado y de la tabla principal  
   - Cerrar pesta√±a y regresar a resultados  
4. Consolidar registros y exportar un CSV final deduplicado por `car_id`.

Este enfoque separa la extracci√≥n de listado (localizar veh√≠culos/URL) y la extracci√≥n de detalle (capturar variables completas por anuncio).
""")

st.write("")

# ------------------------------------------------------------
# Variables capturadas
# ------------------------------------------------------------
with st.container(border=True):
    st.header("üßæ Variables capturadas y estructura del registro")
    st.markdown("""
Cada anuncio se almacen√≥ como una observaci√≥n (fila) con variables provenientes de dos fuentes:

**Encabezado del anuncio**
- t√≠tulo, marca, modelo  
- a√±o (parseado desde el t√≠tulo cuando aplica)  
- precio en colones y precio en d√≥lares (cuando est√° disponible)

**Tabla de caracter√≠sticas**
- cilindrada, estilo, combustible, transmisi√≥n, estado  
- kilometraje, colores, puertas, pasajeros, provincia  
- fecha de ingreso e indicadores comerciales (negociable, impuestos pagados, recibe veh√≠culo), entre otras

Adicionalmente, se registraron variables t√©cnicas para trazabilidad:
- `car_id` (identificador √∫nico)  
- `detail_url` (URL visitada)  
- `pagina` y `posicion_en_pagina` (auditor√≠a/depuraci√≥n)  
""")

st.write("")

# ------------------------------------------------------------
# Estabilidad y contingencias
# ------------------------------------------------------------
with st.container(border=True):
    st.header("üßØ Control de estabilidad, errores y contingencias")
    st.markdown("""
Se incorporaron mecanismos expl√≠citos de robustez:

- **Errores HTTP 500 y fallos de carga:** reintentos con backoff exponencial y jitter; omisi√≥n del anuncio tras m√∫ltiples intentos fallidos.  
- **Control de ritmo:** pausas entre detalles y p√°ginas (`SLEEP_BETWEEN_DETAILS`, `SLEEP_BETWEEN_PAGES`) con aleatoriedad controlada.  
- **Checkpoints y reanudaci√≥n:** guardado peri√≥dico del progreso (`__last_page`, `__last_idx`, `seen_ids`) y de los registros extra√≠dos.  
- **Auto-restart del driver:** ante fallos de sesi√≥n, guardado de checkpoint, reinicio del WebDriver y retorno al √∫ltimo punto procesado.  
- **Deduplicaci√≥n:** salida final deduplicada por `car_id`.  
""")
    st.warning("Nota: Algunos anuncios pueden omitirse si presentan fallos persistentes de carga o error del sitio.")

st.write("")

# ------------------------------------------------------------
# Salidas del proceso
# ------------------------------------------------------------
with st.container(border=True):
    st.header("üì¶ Salidas del proceso")
    st.markdown("""
El pipeline gener√≥:

- **Checkpoints (intermedios):** recuperaci√≥n de progreso y auditor√≠a de extracci√≥n  
- **Archivo final por corrida:** anuncios extra√≠dos para el rango de a√±os indicado, deduplicado por `car_id`  

Posteriormente, los archivos finales por rango/a√±o se consolidaron en un √∫nico dataset maestro (descrito en la fase de preparaci√≥n o en un anexo t√©cnico).
""")

st.write("")

# ------------------------------------------------------------
# Consideraciones y limitaciones
# ------------------------------------------------------------
with st.container(border=True):
    st.header("üß© Consideraciones y limitaciones")
    st.markdown("""
- Los datos reflejan el **precio publicado**, no el precio real de transacci√≥n.  
- La calidad de ciertos campos depende del ingreso manual del anunciante.  
- Algunos anuncios pueden omitirse por fallos persistentes de carga o errores del sitio.  
- El dataset representa el mercado durante la ventana de extracci√≥n; el mercado es din√°mico y cambia con el tiempo.  
""")

st.write("")

# ------------------------------------------------------------
# Snippet de c√≥digo (ejemplo)
# ------------------------------------------------------------
with st.container(border=True):
    st.header("üíª Snippet de c√≥digo (referencial)")
    st.caption("Ejemplo ilustrativo del patr√≥n usado: b√∫squeda, paginaci√≥n, apertura de detalle en nueva pesta√±a y extracci√≥n con control de errores.")
    st.code(
        """
# (Ejemplo referencial) Flujo t√≠pico del scraping con Selenium

for year_from, year_to in year_ranges:
    apply_filters(driver, year_from=year_from, year_to=year_to, newused=0)
    run_search(driver)

    while not last_page:
        cards = get_result_cards(driver)

        for idx, card in enumerate(cards):
            car_id, detail_url = parse_card(card)

            if car_id in seen_ids:
                continue

            try:
                open_in_new_tab(driver, detail_url)
                record = extract_detail_page(driver, car_id=car_id, page=page, pos=idx)
                results.append(record)
                seen_ids.add(car_id)

            except Exception:
                # reintentos, backoff, skip controlado, logging
                handle_detail_error(car_id, detail_url)

            finally:
                close_tab_and_return(driver)

        go_next_page(driver)
        maybe_checkpoint(results, seen_ids, last_page=page, last_idx=idx)
        """,
        language="python"
    )

st.caption("TFG: Anal√≠tica del mercado de veh√≠culos usados en Costa Rica | Adquisici√≥n de datos")